#!/usr/bin/env python3
"""
ç¼“å­˜æ•°æ®å¤„ç†å™¨æ¨¡å—
æ”¯æŒåœ¨ workflow config ä¸­ä½¿ç”¨çš„ç¼“å­˜æœºåˆ¶
"""

import os
import pickle
import hashlib
from qlib.contrib.data.handler import Alpha158, Alpha360
from qlib.data.dataset.handler import DataHandlerLP


class CachedDataHandlerMixin:
    """ç¼“å­˜æ•°æ®å¤„ç†å™¨æ··å…¥ç±»"""
    
    def __init__(self, *args, cache_dir='~/.qlib/cache/handler/', enable_cache=True, **kwargs):
        super().__init__(*args, **kwargs)
        self.enable_cache = enable_cache
        self.cache_dir = os.path.expanduser(cache_dir)
        if self.enable_cache:
            os.makedirs(self.cache_dir, exist_ok=True)
            # å»¶è¿Ÿç”Ÿæˆç¼“å­˜é”®ï¼Œç›´åˆ° setup_data è°ƒç”¨æ—¶

    def _generate_cache_key(self):
        """ç”Ÿæˆå”¯ä¸€ç¼“å­˜é”®ï¼šåŸºäºclasså + æ—¶é—´èŒƒå›´ + instruments + processors"""
        # æ„å»ºç¼“å­˜é”®çš„ç»„æˆéƒ¨åˆ†ï¼Œä½¿ç”¨ getattr æ¥å®‰å…¨è·å–å±æ€§
        key_components = [
            self.__class__.__name__,
            str(getattr(self, 'start_time', 'unknown')),
            str(getattr(self, 'end_time', 'unknown')),
            str(getattr(self, 'fit_start_time', 'unknown')),
            str(getattr(self, 'fit_end_time', 'unknown')),
            str(sorted(getattr(self, 'instruments', [])) if hasattr(self, 'instruments') and getattr(self, 'instruments', None) else 'all'),
            str(getattr(self, 'infer_processors', [])),
            str(getattr(self, 'learn_processors', [])),
        ]
        
        key_str = '_'.join(key_components)
        return hashlib.md5(key_str.encode()).hexdigest() + '.pkl'

    def setup_data(self, *args, **kwargs):
        """é‡å†™æ•°æ®è®¾ç½®æ–¹æ³•ï¼Œæ·»åŠ ç¼“å­˜é€»è¾‘"""
        # ç¡®ä¿ enable_cache å±æ€§å­˜åœ¨ï¼ˆå¤„ç†å¤šé‡ç»§æ‰¿é¡ºåºé—®é¢˜ï¼‰
        if not hasattr(self, 'enable_cache'):
            self.enable_cache = True
            self.cache_dir = os.path.expanduser('~/.qlib/cache/handler/')
            os.makedirs(self.cache_dir, exist_ok=True)
            
        if not self.enable_cache:
            return super().setup_data(*args, **kwargs)
            
        # åœ¨è¿™é‡Œç”Ÿæˆç¼“å­˜é”®ï¼Œç¡®ä¿æ‰€æœ‰å±æ€§éƒ½å·²è®¾ç½®
        if not hasattr(self, 'cache_key'):
            self.cache_key = self._generate_cache_key()
            
        cache_path = os.path.join(self.cache_dir, self.cache_key)
        
        if os.path.exists(cache_path):
            print(f"ğŸ”„ ä»ç¼“å­˜åŠ è½½æ•°æ®: {os.path.basename(cache_path)}")
            try:
                with open(cache_path, 'rb') as f:
                    cached_data = pickle.load(f)
                
                # æ¢å¤ç¼“å­˜çš„æ•°æ®
                self._data = cached_data.get('_data')
                if hasattr(self, '_infer'):
                    self._infer = cached_data.get('_infer')
                if hasattr(self, '_learn'):
                    self._learn = cached_data.get('_learn')
                
                print(f"âœ… ç¼“å­˜åŠ è½½æˆåŠŸï¼Œæ•°æ®å½¢çŠ¶: {self._data.shape if self._data is not None else 'None'}")
                return
                
            except Exception as e:
                print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®¡ç®—: {str(e)}")
        
        # ç¼“å­˜ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®¡ç®—
        print(f"ğŸ”§ é‡æ–°è®¡ç®—æ•°æ®å¹¶ç¼“å­˜åˆ°: {os.path.basename(cache_path)}")
        super().setup_data(*args, **kwargs)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            cache_data = {'_data': self._data}
            if hasattr(self, '_infer'):
                cache_data['_infer'] = self._infer
            if hasattr(self, '_learn'):
                cache_data['_learn'] = self._learn
                
            with open(cache_path, 'wb') as f:
                pickle.dump(cache_data, f)
            print(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜ï¼Œæ–‡ä»¶å¤§å°: {os.path.getsize(cache_path) / 1024 / 1024:.1f}MB")
            
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")


class CachedAlpha158(CachedDataHandlerMixin, Alpha158):
    """å¸¦ç¼“å­˜çš„ Alpha158 æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, *args, cache_dir='~/.qlib/cache/handler/', enable_cache=True, **kwargs):
        # æ˜¾å¼æå–ç¼“å­˜ç›¸å…³å‚æ•°ï¼Œç¡®ä¿å®ƒä»¬è¢«æ­£ç¡®ä¼ é€’
        self._cache_dir = cache_dir
        self._enable_cache = enable_cache
        super().__init__(*args, cache_dir=cache_dir, enable_cache=enable_cache, **kwargs)


class CachedAlpha360(CachedDataHandlerMixin, Alpha360):
    """å¸¦ç¼“å­˜çš„ Alpha360 æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, *args, cache_dir='~/.qlib/cache/handler/', enable_cache=True, **kwargs):
        self._cache_dir = cache_dir
        self._enable_cache = enable_cache
        super().__init__(*args, cache_dir=cache_dir, enable_cache=enable_cache, **kwargs)


class CachedDataHandlerLP(CachedDataHandlerMixin, DataHandlerLP):
    """å¸¦ç¼“å­˜çš„é€šç”¨æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, *args, cache_dir='~/.qlib/cache/handler/', enable_cache=True, **kwargs):
        self._cache_dir = cache_dir
        self._enable_cache = enable_cache
        super().__init__(*args, cache_dir=cache_dir, enable_cache=enable_cache, **kwargs)


# ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›åˆ«å
CachedDataHandler = CachedDataHandlerLP 